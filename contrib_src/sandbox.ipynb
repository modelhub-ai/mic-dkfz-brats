{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how use the model api to run predictions and get information from the model. You can use it as basis to write your own experiements using the model in this container.\n",
    "\n",
    "To start, import _modelapi.model_, which will give us access to the api of the model in this container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modelapi import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other helpful imports for this demo\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Various ways of handing data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either load the necessary input for the prediction from a file:\n",
    "input = 'sample_data/sample.json'\n",
    "# or assemble a dictionary for yourself \n",
    "input_dict = {\"t1\":{},\"t2\":{},\"flair\":{},\"t1c\":{}}\n",
    "# mandatory: fileurl for each input!\n",
    "input_dict[\"t1\"][\"fileurl\"] = 'sample_data/patient_1/t1.nii.gz'\n",
    "# mandatory: format for each input, be aware that this has to be a list:\n",
    "input_dict[\"t1\"][\"format\"] = [\"application/nii-gzip\"]\n",
    "# and so on for each other input.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input, \"r\") as f:\n",
    "    input_dict_from_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint model/params/0/model_best.model train= False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/contrib_src/predict.py:286: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  stacked = stacked[slicer]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint model/params/1/model_best.model train= False\n",
      "loading checkpoint model/params/2/model_best.model train= False\n",
      "loading checkpoint model/params/3/model_best.model train= False\n",
      "loading checkpoint model/params/4/model_best.model train= False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# you can then simply pass your input to the model:\n",
    "result = model.predict(input_dict_from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'id': '14e79015-ae1d-49b7-9673-032f6e441d3d',\n",
       "  'name': 'mic-dkfz-brats'},\n",
       " 'output': [{'description': 'Numpy array of shape (240,240,155) with labels. Needs header from one of the input images to save to file.',\n",
       "   'name': 'Segmentation',\n",
       "   'prediction': 'api/output/2019-09-24-15-18-06-847454.h5',\n",
       "   'shape': [155, 240, 240],\n",
       "   'type': 'image'}],\n",
       " 'processing_time': 25.019,\n",
       " 'timestamp': '2019-09-24-15-18-06-851703'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what the output contains:\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recover a prediction from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Segmentation']\n",
      "Shape of prediction is: (155, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "# recover prediction from h5 file\n",
    "resultFile = result[\"output\"][0][\"prediction\"].replace(\"api\", \"\")\n",
    "f = h5py.File(resultFile, 'r')\n",
    "print(list(f.keys()))\n",
    "# load the actual prediction and check for correct shape\n",
    "prediction = f[\"Segmentation\"]\n",
    "print('Shape of prediction is: {}'.format(prediction.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just plot one slice to see if it returns a sensible result \n",
    "plt.imshow(prediction[90])\n",
    "print(prediction[90].max(), prediction[90].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the result as a Nifti-1 file so we can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we have to swap the axes of the array to match the shape of the original images (155,240,240) -> (240,240,155)\n",
    "prediction = np.swapaxes(prediction, 0,2)\n",
    "# second, we load the metadata from one of the input images to populate the header:\n",
    "affine = load_nifti('sample_data/patient_1/flair.nii.gz')[1]\n",
    "save_nifti('sample_data/patient_1/segmentation.nii.gz', prediction, affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model does not provide any sample data, print an error message (this part also shows how to read meta info - like the model's name - from the models config)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
